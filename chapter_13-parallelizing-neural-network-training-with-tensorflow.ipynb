{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelizing Neural Network Training with Tensorflow\n",
    "\n",
    "## First Steps with Tensorflow\n",
    "\n",
    "Let's tart by exploring tensorflow's low level API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  1.0 --> z =  2.7\n",
      "x =  0.6 --> z =  1.9\n",
      "x = -1.8 --> z = -2.9\n"
     ]
    }
   ],
   "source": [
    "# create a graph\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    x = tf.placeholder(dtype=tf.float32,\n",
    "                      shape=(None),\n",
    "                      name='x')\n",
    "    w = tf.Variable(2.0, name='weight')\n",
    "    b = tf.Variable(0.7, name='bias')\n",
    "    \n",
    "    z = w*x + b\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "# create session and pass in graph g\n",
    "with tf.Session(graph=g) as sess:\n",
    "    # initalize w and b\n",
    "    sess.run(init)\n",
    "    # evaluate z\n",
    "    for t in [1.0, 0.6, -1.8]:\n",
    "        print ('x = %4.1f --> z = %4.1f' % (t, sess.run(z, feed_dict={x:t})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Array Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  (3, 2, 3)\n",
      "Reshaped\n",
      " [[ 0.  1.  2.  3.  4.  5.]\n",
      " [ 6.  7.  8.  9. 10. 11.]\n",
      " [12. 13. 14. 15. 16. 17.]]\n",
      "Column Sums \n",
      " [18. 21. 24. 27. 30. 33.]\n",
      "Column Means \n",
      " [ 6.  7.  8.  9. 10. 11.]\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    x = tf.placeholder(dtype=tf.float32,\n",
    "                       shape=(None, 2, 3),\n",
    "                       name='input_x')\n",
    "    \n",
    "    x2 = tf.reshape(x, shape=(-1, 6),\n",
    "                   name='x2')\n",
    "    \n",
    "    \n",
    "    ## calculate the sum of each column\n",
    "    xsum = tf.reduce_sum(x2, axis=0, name='col_sum')\n",
    "    ## calcualte the mean of each column\n",
    "    xmean = tf.reduce_mean(x2, axis=0, name='col_mean')\n",
    "    \n",
    "with tf.Session(graph=g) as sess:\n",
    "    x_array = np.arange(18).reshape(3,2,3)\n",
    "    \n",
    "    print ('input shape: ', x_array.shape)\n",
    "    print ('Reshaped\\n', sess.run(x2, feed_dict={x:x_array}))\n",
    "    print ('Column Sums \\n', sess.run(xsum, feed_dict={x:x_array}))\n",
    "    print ('Column Means \\n', sess.run(xmean, feed_dict={x:x_array}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing a Simple Model with the Low-Level Tensorflow API\n",
    "\n",
    "Let's implement an OLS regression using Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/zach/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "X_train = np.arange(10).reshape((10, 1))\n",
    "y_train = np.array([1.0, 1.3, 3.1,\n",
    "                   2.0, 5.0, 6.3,\n",
    "                   6.6, 7.4, 8.0,\n",
    "                   9.0])\n",
    "\n",
    "# create a linear regression using tensorflow\n",
    "class TfLinReg(object):\n",
    "    def __init__(self, x_dim, learning_rate=0.01, random_seed=None):\n",
    "        self.x_dim = x_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.g = tf.Graph()\n",
    "        ## build the model\n",
    "        with self.g.as_default():\n",
    "            ## set graph level random seed\n",
    "            tf.set_random_seed(random_seed)\n",
    "            \n",
    "            self.build()\n",
    "            ## create initializer\n",
    "            self.init_op = tf.global_variables_initializer()\n",
    "            \n",
    "    def build(self):\n",
    "        ## define placeholders for inputs\n",
    "        self.X = tf.placeholder(dtype=tf.float32,\n",
    "                               shape=(None, self.x_dim),\n",
    "                               name='x_input')\n",
    "        self.y = tf.placeholder(dtype=tf.float32,\n",
    "                               shape=(None),\n",
    "                               name='y_input')\n",
    "        \n",
    "        ## define weight matrix and bias vector\n",
    "        w = tf.Variable(tf.zeros(shape=(1)),\n",
    "                       name='weight')\n",
    "        b = tf.Variable(tf.zeros(shape=(1)),\n",
    "                       name='bias')\n",
    "        \n",
    "        self.z_net = tf.squeeze(w*self.X + b,\n",
    "                               name='z_net')\n",
    "        \n",
    "        sqr_errors = tf.square(self.y - self.z_net,\n",
    "                              name='sqr_errors')\n",
    "        \n",
    "        \n",
    "        self.mean_cost = tf.reduce_mean(sqr_errors,\n",
    "                                       name='mean_cost')\n",
    "        \n",
    "        optimizer = tf.train.GradientDescentOptimizer(\n",
    "                    learning_rate=self.learning_rate,\n",
    "                    name='GradientDescent')\n",
    "        \n",
    "        self.optimizer = optimizer.minimize(self.mean_cost)\n",
    "        \n",
    "# instantiate model\n",
    "lrmodel = TfLinReg(x_dim=X_train.shape[1])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a separate function to train our OLS model\n",
    "def train_linreg(sess, model, X_train, y_train, num_epochs=10):\n",
    "    ## initialize all variables: W and b\n",
    "    sess.run(model.init_op)\n",
    "    \n",
    "    training_costs = []\n",
    "    for i in range(num_epochs):\n",
    "        _, cost = sess.run([model.optimizer, model.mean_cost],\n",
    "                          feed_dict={model.X:X_train,\n",
    "                                    model.y:y_train})\n",
    "        training_costs.append(cost)\n",
    "    \n",
    "    return training_costs\n",
    "\n",
    "sess = tf.Session(graph=lrmodel.g)\n",
    "training_costs = train_linreg(sess, lrmodel, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1, len(training_costs)+1), training_costs)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Costs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing a Multilayer Neural Network with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "import os\n",
    "import numpy as np\n",
    "import struct\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"\n",
    "    Load MNIST data from 'path'\n",
    "    \"\"\"\n",
    "    labels_path = os.path.join(path, '%s-labels-idx1-ubyte' % kind)\n",
    "    images_path = os.path.join(path, '%s-images-idx3-ubyte' % kind)\n",
    "    \n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II',\n",
    "                                lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath,\n",
    "                            dtype=np.uint8)\n",
    "        \n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII',\n",
    "                                              imgpath.read(16))\n",
    "        images = np.fromfile(imgpath,\n",
    "                            dtype=np.uint8).reshape(len(labels), 784)\n",
    "        images = ((images / 255.) - 0.5) * 2\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "X_train, y_train = load_mnist('', kind='train')\n",
    "X_test, y_test = load_mnist('', kind='t10k')\n",
    "\n",
    "## mean centering and normalization\n",
    "mean_vals = np.mean(X_train, axis=0)\n",
    "std_val = np.std(X_train)\n",
    "\n",
    "X_train_centered = (X_train - mean_vals) / std_val\n",
    "X_test_centered = (X_test - mean_vals) / std_val\n",
    "\n",
    "del X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "tf.set_random_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_onehot = keras.utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        units=50,\n",
    "        input_dim=X_train_centered.shape[1],\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='tanh'))\n",
    "\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        units=50,\n",
    "        input_dim=50,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='tanh'))\n",
    "\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        units=y_train_onehot.shape[1],\n",
    "        input_dim=50,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='softmax'))\n",
    "\n",
    "sgd_optimizer = keras.optimizers.SGD(\n",
    "    lr=0.001, decay=1e-7, momentum=0.9)\n",
    "\n",
    "model.compile(optimizer=sgd_optimizer,\n",
    "             loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/50\n",
      "54000/54000 [==============================] - 2s 41us/sample - loss: 0.7420 - val_loss: 0.3742\n",
      "Epoch 2/50\n",
      "54000/54000 [==============================] - 1s 25us/sample - loss: 0.3776 - val_loss: 0.2794\n",
      "Epoch 3/50\n",
      "54000/54000 [==============================] - 2s 28us/sample - loss: 0.3105 - val_loss: 0.2403\n",
      "Epoch 4/50\n",
      "54000/54000 [==============================] - 1s 25us/sample - loss: 0.2734 - val_loss: 0.2159\n",
      "Epoch 5/50\n",
      "54000/54000 [==============================] - 1s 27us/sample - loss: 0.2477 - val_loss: 0.1985 \n",
      "Epoch 6/50\n",
      "54000/54000 [==============================] - 1s 26us/sample - loss: 0.2275 - val_loss: 0.1845\n",
      "Epoch 7/50\n",
      "54000/54000 [==============================] - 1s 27us/sample - loss: 0.2112 - val_loss: 0.1721s - l - ETA: 0s - loss\n",
      "Epoch 8/50\n",
      "54000/54000 [==============================] - 1s 27us/sample - loss: 0.1975 - val_loss: 0.1640\n",
      "Epoch 9/50\n",
      "54000/54000 [==============================] - 2s 31us/sample - loss: 0.1859 - val_loss: 0.1561\n",
      "Epoch 10/50\n",
      "54000/54000 [==============================] - 2s 31us/sample - loss: 0.1757 - val_loss: 0.1488ETA: 0s - l\n",
      "Epoch 11/50\n",
      "54000/54000 [==============================] - 2s 37us/sample - loss: 0.1665 - val_loss: 0.1431\n",
      "Epoch 12/50\n",
      "54000/54000 [==============================] - 2s 32us/sample - loss: 0.1583 - val_loss: 0.1378\n",
      "Epoch 13/50\n",
      "54000/54000 [==============================] - 2s 29us/sample - loss: 0.1510 - val_loss: 0.1334\n",
      "Epoch 14/50\n",
      "54000/54000 [==============================] - 2s 30us/sample - loss: 0.1444 - val_loss: 0.1297\n",
      "Epoch 15/50\n",
      "54000/54000 [==============================] - 1s 27us/sample - loss: 0.1383 - val_loss: 0.1261\n",
      "Epoch 16/50\n",
      "54000/54000 [==============================] - 2s 28us/sample - loss: 0.1327 - val_loss: 0.1233\n",
      "Epoch 17/50\n",
      "54000/54000 [==============================] - 2s 29us/sample - loss: 0.1275 - val_loss: 0.1213\n",
      "Epoch 18/50\n",
      "54000/54000 [==============================] - 2s 28us/sample - loss: 0.1227 - val_loss: 0.1182\n",
      "Epoch 19/50\n",
      "54000/54000 [==============================] - 2s 28us/sample - loss: 0.1182 - val_loss: 0.1161\n",
      "Epoch 20/50\n",
      "54000/54000 [==============================] - 1s 26us/sample - loss: 0.1139 - val_loss: 0.1144\n",
      "Epoch 21/50\n",
      "54000/54000 [==============================] - 1s 27us/sample - loss: 0.1100 - val_loss: 0.1128\n",
      "Epoch 22/50\n",
      "54000/54000 [==============================] - 1s 27us/sample - loss: 0.1063 - val_loss: 0.1113\n",
      "Epoch 23/50\n",
      "54000/54000 [==============================] - 2s 29us/sample - loss: 0.1029 - val_loss: 0.1100\n",
      "Epoch 24/50\n",
      "54000/54000 [==============================] - 2s 29us/sample - loss: 0.0995 - val_loss: 0.1095\n",
      "Epoch 25/50\n",
      "54000/54000 [==============================] - 1s 27us/sample - loss: 0.0964 - val_loss: 0.1089\n",
      "Epoch 26/50\n",
      "54000/54000 [==============================] - 1s 26us/sample - loss: 0.0933 - val_loss: 0.1075\n",
      "Epoch 27/50\n",
      "54000/54000 [==============================] - 1s 26us/sample - loss: 0.0906 - val_loss: 0.1067\n",
      "Epoch 28/50\n",
      "54000/54000 [==============================] - 1s 26us/sample - loss: 0.0880 - val_loss: 0.1063\n",
      "Epoch 29/50\n",
      "54000/54000 [==============================] - 1s 26us/sample - loss: 0.0854 - val_loss: 0.1056\n",
      "Epoch 30/50\n",
      "54000/54000 [==============================] - 1s 27us/sample - loss: 0.0829 - val_loss: 0.1053\n",
      "Epoch 31/50\n",
      "54000/54000 [==============================] - 2s 28us/sample - loss: 0.0806 - val_loss: 0.1048\n",
      "Epoch 32/50\n",
      "54000/54000 [==============================] - 2s 28us/sample - loss: 0.0783 - val_loss: 0.1043\n",
      "Epoch 33/50\n",
      "54000/54000 [==============================] - 2s 29us/sample - loss: 0.0761 - val_loss: 0.1037\n",
      "Epoch 34/50\n",
      "54000/54000 [==============================] - 1s 26us/sample - loss: 0.0741 - val_loss: 0.1036\n",
      "Epoch 35/50\n",
      "54000/54000 [==============================] - 1s 27us/sample - loss: 0.0721 - val_loss: 0.1036\n",
      "Epoch 36/50\n",
      "54000/54000 [==============================] - 2s 28us/sample - loss: 0.0701 - val_loss: 0.1034s - l\n",
      "Epoch 37/50\n",
      "54000/54000 [==============================] - 1s 27us/sample - loss: 0.0681 - val_loss: 0.1027\n",
      "Epoch 38/50\n",
      "54000/54000 [==============================] - 1s 26us/sample - loss: 0.0664 - val_loss: 0.1026\n",
      "Epoch 39/50\n",
      "54000/54000 [==============================] - 1s 26us/sample - loss: 0.0646 - val_loss: 0.1039\n",
      "Epoch 40/50\n",
      "54000/54000 [==============================] - 1s 27us/sample - loss: 0.0629 - val_loss: 0.1035: 0s - loss\n",
      "Epoch 41/50\n",
      "54000/54000 [==============================] - 2s 28us/sample - loss: 0.0613 - val_loss: 0.1021.0\n",
      "Epoch 42/50\n",
      "54000/54000 [==============================] - 1s 27us/sample - loss: 0.0597 - val_loss: 0.1024\n",
      "Epoch 43/50\n",
      "54000/54000 [==============================] - 1s 27us/sample - loss: 0.0582 - val_loss: 0.1035\n",
      "Epoch 44/50\n",
      "54000/54000 [==============================] - 2s 30us/sample - loss: 0.0568 - val_loss: 0.1019\n",
      "Epoch 45/50\n",
      "54000/54000 [==============================] - 2s 30us/sample - loss: 0.0554 - val_loss: 0.10210\n",
      "Epoch 46/50\n",
      "54000/54000 [==============================] - 2s 30us/sample - loss: 0.0539 - val_loss: 0.1024\n",
      "Epoch 47/50\n",
      "54000/54000 [==============================] - 2s 30us/sample - loss: 0.0525 - val_loss: 0.1025\n",
      "Epoch 48/50\n",
      "54000/54000 [==============================] - 2s 30us/sample - loss: 0.0513 - val_loss: 0.1019\n",
      "Epoch 49/50\n",
      "54000/54000 [==============================] - 1s 27us/sample - loss: 0.0500 - val_loss: 0.1024\n",
      "Epoch 50/50\n",
      "54000/54000 [==============================] - 2s 32us/sample - loss: 0.0487 - val_loss: 0.1025\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_centered,\n",
    "                   y_train_onehot,\n",
    "                   batch_size=64,\n",
    "                   epochs=50,\n",
    "                   verbose=1,\n",
    "                   validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9884\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict_classes(X_train_centered, verbose=0)\n",
    "correct_preds = np.sum(y_train_pred == y_train, axis=0)\n",
    "print ('Training Accuracy:', correct_preds / y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.964\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict_classes(X_test_centered, verbose=0)\n",
    "correct_preds = np.sum(y_test_pred == y_test, axis=0)\n",
    "print ('Testing Accuracy:', correct_preds / y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
